---
author: La Fondation Internet Nouvelle Génération (auteur invité)
description: On the 26th of September, the Fing held its first Our Systemsworkshop, organized within its mission with Etalab, on the subject of the exemplarity and social responsibility of public algorithms. Several Public Interest Entrepreneur program projects have participated such as DataESR, Hopkins, Tell-tell signs, OpenChronic or LabSanté, as well as Fing partners such as Orange, EDF and La Poste. Learn more on what was done and future steps.
image: /img/blog/atelier-fing-algo-ensemble.jpg
layout: post
tags:
- partenariat
- algorithme
title: Establishing exemplary public algorithms, the Fing-Etalab mission has been launched with the EIG Promotion 2!
permalink: /en/blog/:year/:month/:day/:title.html
lang-ref: fing-algo
twitter: la_fing
---

_This article was written by Fling&#39;s Our Systems team: Hubert Guillaud and Thierry Marcou. Thanks to the Fing, Simon Chignard and Loup Cellard for leading this workshop!_

On 26 September, the Fing held its first [Our Systems](http://fing.org/?NosSystemes)workshop, organized within its mission with Etalab, on the subject of **the exemplarity and social responsibility of public algorithms**. This exploration subject echoes the provisions of the law for a digital Republic on the transparency and explanability of algorithms and mediation projects based on algorithms produced within[Etalab](https://www.etalab.gouv.fr/) (housing tax, tax calculator, APB).

**Several Public Interest Entrepreneur program projects have participated such as DataESR, Hopkins, Tell-tell signs, OpenChronic or LabSanté, as well as Fing partners such as Orange, EDF and La Poste.**

This was our first real working session with Public Interest Entrepreneurs. To get to know them better, we organized the workshop around three questionnaires:

- The first **Cross-Portraits** questionnaire asked participants about their ability to meet their legal obligations to provide information about the algorithmic processing they implement.
- The second questionnaire explored the question of the **forms of mediation implemented, or otherwise, in dialoguing with individuals or legal entities subject to their algorithms**.
- The last questionnaire explored the various **strategies for explaining algorithmic processing**.

![Atelier ensemble](/img/blog/atelier-fing-algo-ensemble.jpg)
_EIGs, as Fing and Etalab partners, participate in the questionnaires._

These questionnaires had no scientific pretension, our main objective being to stimulate debate and discussions during the workshop. From this standpoint it was a success!

## Surprise report

Here is some of the feedback from our discussions.

**Does the purpose of the calculation or processing on the one hand need to be distinguished from the purpose of the service on the other?** The purpose of the Tell-tell signs service is to predict business failures earlier, while the purpose of the algorithmic processing implemented is to provide scoring. The provisional solution found was to make things clearer, for example by distinguishing between the purpose of the service and the purpose of the algorithm, or even by reserving the purpose for the service and the functionality for the algorithm. The non-technical dialogue on the technology we would like to see can only be fostered by this type of debate.

**An algorithmic system addresses at least two different audiences. Those they calculate of course, but also those who use it in the more general framework of their assignment**. We will need to explore these two concepts, in terms of what is common to them and what is not.

- The DIRECCTE of the Burgundy-Franche-Comté region benefits from the Tell-tell signs scoring algorithm, with companies being the ones that are &quot;calculated&quot;.
- Some algorithms are not concerned by the law, as they do not result in individual processing such as DataESR, and have &quot;internal&quot; users rather than calculated subjects. These are &quot;process&quot; algorithms. But this still has to be able to be explained in-house. Explanability is not only something owed to calculated subjects, but also to users, who are not only end users, but can also be, for example, supervisory authorities, principals, etc.

![Matrice exemplarité](/img/blog/atelier-fing-algo-systeme-2.jpg)
_An initial exemplarity matrix for public algorithms: responsibility through mediation, explanability, playability, symmetry and justiciability._

**Answers can sometimes be surprising, for example, when algorithms are said to be &quot;playable&quot; because their source code is open**. This is an old debate, which is probably finding a new lease of life with the subject of algorithms.

- Yes, the opening up of the code allows researchers, hackers and other citizen groups to advance in understanding algorithmic systems and in detecting their flaws.
- No, opening up of code is not enough, as the step to be climbed is still too high for the vast majority of calculated subjects and users.
- Furthermore, could it perhaps not be said that too much attention is given to algorithms and not enough to data? Although a majority of participants indicated that they provided information on the sources of the data used, there are certainly avenues to be explored to provide further information about the type of data and how it was selected, sorted or cleaned up.

## Next stage: a week of Intensive Design with the Boulle and ENS-Cachan schools

**This first workshop will of course foster the next step, which will take the form of an &quot;Intensive Design&quot; workshop with the Boulle and ENS-Cachan schools. The argument given to students was as follows** :

&quot;_Automated processing systems are becoming increasingly common in public services, such as the challenge services provided by the Public interest entrepreneur program (EIG). These technical systems, whether they are intended for the general public or for government departments, nevertheless have to meet multiple legal obligations regardless of the users they are intended for. How can we make these services exemplary? How can they make their purposes clear to their audiences? How can their procedures be improved to better meet the demands of the audiences they calculate? How can their playability, justiciability and accountability be improved? &quot;_

The challenge of this workshop is to confront innovative public services being established with proposals from young designers to improve their social impact.

**For this next stage, we are therefore looking for volunteer EIG projects and other projects related to public algorithms to present their projects in detail to students, answer their questions and establish with them the directions and perspectives they will explore during these ten days. 20 students (12 from the Boulle school and 8 from ENS-Cachan school) and their teachers will be involved for you.**

**The schedule for this &quot;Intensive Design&quot; workshop is as follows** :

- The workshop will take place on 7-16 November 2018, in the premises of the Boulle school in Paris
- Beforehand, Fing will present the issues and aims of the workshop to students on Friday, 26 October
- Wednesday, 7 November, 9am-1pm, Boulle school: Pitching of projects before students
- Friday 16 November, 9am-1pm: submitting of proposals and prototypes made by the students

Feel free to contact us very quickly if you want to be an applicant! The deadlines are rather short. But working with students is always very refreshing!

[**Link to the presentation made on 26 September 2018**](https://speakerdeck.com/eig2018/atelier-fing-etalab-eig-sur-les-algorithmes-publics-4f099df8-7506-48ea-ae65-1015dde0a07c)

**Contacts:**

- [tmarcou@fing.org](mailto:tmarcou@fing.org)
- [hguillaud@fing.org](mailto:hguillaud@fing.org)
- [entrepreneur-interet-general@data.gouv.fr](mailto:entrepreneur-interet-general@data.gouv.fr)
